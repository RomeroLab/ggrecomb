"""Functions for dealing with recombinant protein libraries.

This module provides the definition of :class:`ggrecomb.Library`, which
represents a library of recombinant proteins, and functions for analyzing and
manipulating libraries.

"""

from dataclasses import dataclass
from functools import cached_property
from itertools import combinations

from ggrecomb.energy_functions import EnergyFunction
from ggrecomb import ParentSequences


@dataclass
class _Library:
    """Recombinant protein library.

    This class is not usually instantiated by users, but generated by something
    else.

    A library consists of a parent alignment and a series of breakpoints, which
    are the indices of the alignment which the parent sequences are recombined
    with Golden Gate assembly to form recombinants.

    Each library is assigned a metric of energy and mutation_rate that estimate
    the fraction of functional recombinants and sequence diversity,
    respectively. The exact metrics depend on the method used to optimize over
    the recombinant space. For example, the SCHEMA-RASPP algorithm averages the
    SCHEMA energy and minimum number of mutations from a parent sequence over
    every recombinant protein in the library. See Endelman et al. 2004 for more
    details about SCHEMA-RASPP.

    Each library is also assigned a "Golden Gate probability" that estimates
    the efficiency of library assembly given the optimal set of Golden Gate
    overhangs chosen for the given library. This value is computed (and
    overhangs chosen) based on data from Gregory Lohman and collaborators at
    NEB (Potapov et al. 2018). See Pryor, Potapov, et al. 2020 for details on
    the biology and mathematics behind this technique. (Note that the
    calculation was developed independently by the authors of ggrecomb in 2019
    after viewing a talk by Dr. Lohman.)

    The attributes for this class are the same as the parameters.

    Parameters:
        breakpoints: Alignment indices where the parent sequences are
            recombined to form the recombinants in the Library.
        parent_alignment: Alignment of parent protein sequences that will
            be recombined.
        energy: Estimation of the fraction of functional recombinants relative
            to other libraries from the same parent alignment. High energy
            libraries are likely to have a larger proportion of active enzymes.
            The interpretation of this value depends on the EnergyFunction
            used to calculate it, which must be passed in as the
            energy_function parameter.
        energy_function: The EnergyFunction used the calculate the energy
            attribute.
        mutation_rate: Average mutational distance to closest parent for each
            recombinant in the library.

    """

    breakpoints: dict[int, list[tuple[int, str]]]
    parent_alignment: ParentSequences
    energy: float
    energy_function: EnergyFunction
    mutation_rate: float

    @cached_property
    def min_block_len(self):
        bps = sorted(self.breakpoints)
        return min(bp2 - bp1 for bp1, bp2 in zip(bps, bps[1:]))

    @cached_property
    def max_block_len(self):
        bps = sorted(self.breakpoints)
        return max(bp2 - bp1 for bp1, bp2 in zip(bps, bps[1:]))

    '''
    def expand(self, e_diff: float, new_bp: dict[int, list[tuple[int, str]]]):
        new_e = self.energy + e_diff
        new_bps = self.breakpoints | new_bp
        return type(self)(new_e, new_bps, self.parent_alignment)
    '''

    '''
    def calc_average_m_naive(self, pa: ParentAlignment, bp_to_group,
                             group_bp_cache):
        """Calculate the average number of mutations in library.

        Naive way to calculate <M>. Currently kept for testing purposes, may be
        deleted later for simplicity.
        """
        def calc_muts(seq1, seq2):
            return sum(1 for a1, a2 in zip(seq1, seq2) if a1 != a2)

        bps = tuple(self.breakpoints)

        # ADDITION
        bp_groups = tuple(bp_to_group[bp] for bp in bps)
        if (m := group_bp_cache.get(bp_groups)) is not None:
            self._m = m
            return m
        # END ADDITION

        p_seqs = [str(sr.seq) for sr in pa.aligned_sequences]

        p = len(p_seqs)  # number of parents
        N = len(p_seqs[0])  # number of amino acids in alignment

        # bps must be (0, ..., N).
        if bps[0] != 0:
            bps = (0,) + bps
        if bps[-1] != N:
            bps += (N,)

        n = len(bps) - 2  # number of crossovers. number of blocks is n+1

        # Construct all library chimeras to calculate average mutations.
        total_muts = 0
        for i, block_parents in enumerate(product(p_seqs, repeat=n+1)):
            # Construct chimera from parent blocks.
            block_seqs = [blkpar[start: end] for blkpar, start, end
                          in zip(block_parents, bps, bps[1:])]
            chimera = ''.join(block_seqs)

            # Chimera m is the number of mutations from the closest parent.
            total_muts += min(calc_muts(chimera, parent) for parent in p_seqs)

        m = total_muts / p**(n+1)

        # ADDITION
        # global group_bp_map
        group_bp_cache[bp_groups] = m
        # END ADDITION

        self._m = m
        return m
    '''

    def calc_average_m(self, pa: ParentSequences, bp_to_group, group_bp_cache):
        """Calculate the average number of mutations in library."""
        def sequence_mutations(seq1, seq2):
            """Hamming distance between seq1 and seq2."""
            assert len(seq1) == len(seq2)
            return sum(1 for a1, a2 in zip(seq1, seq2) if a1 != a2)

        print(bp_to_group)
        print(group_bp_cache)
        if bp_to_group is not None and group_bp_cache is not None:
            bp_groups = tuple(bp_to_group[bp] for bp in self.breakpoints)
            if (M := group_bp_cache.get(bp_groups)) is not None:
                self._m = M
                return M

        seqs = list(zip(*pa.alignment))
        blmuts = []
        bps = sorted(self.breakpoints)
        for bp1, bp2 in zip(bps, bps[1:]):
            muts = {i: {i: 0} for i, _ in enumerate(seqs)}
            for (i, s1), (j, s2) in combinations(enumerate(seqs), 2):
                s1_slice = s1[bp1:bp2]
                s2_slice = s2[bp1:bp2]
                m = sequence_mutations(s1_slice, s2_slice)
                muts[i][j] = m
                muts[j][i] = m
            blmuts.append(muts)

        # Calculate parameters for mutation calculation.
        num_blocks = len(self.breakpoints) - 1
        num_parents = len(seqs)

        # Perform depth first traversal over blocks to calculate M_sum. This
        # is faster than itertools.product because it avoids redundant
        # summation.
        stack = [(1, [blmuts[0][p1][p2] for p2 in range(num_parents)])
                 for p1 in range(num_parents)]
        M_sum = 0
        while stack:
            i, par_muts = stack.pop()
            par_iter = list(zip(par_muts, range(num_parents)))
            block_muts = blmuts[i]
            for p1 in range(num_parents):
                p_muts = block_muts[p1]
                new_part_muts = [m + p_muts[p2] for m, p2 in par_iter]
                if i + 1 == num_blocks:
                    M_sum += min(new_part_muts)
                else:
                    stack.append((i + 1, new_part_muts))

        M = M_sum / num_parents**num_blocks
        self._m = M

        if bp_to_group is not None and group_bp_cache is not None:
            group_bp_cache[bp_groups] = M

        return M
